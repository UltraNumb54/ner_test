# inference_improved.py
import json
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForTokenClassification
import re
import os
from collections import defaultdict

class ImprovedNERPredictor:
    def __init__(self, model_path):
        """
        Инициализация улучшенной NER модели
        """
        print(f"Загрузка модели из {model_path}...")
        
        # Проверяем существование пути
        if not os.path.exists(model_path):
            print(f"Ошибка: путь {model_path} не существует!")
            return None
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.model = AutoModelForTokenClassification.from_pretrained(model_path)
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            print(f"Используется устройство: {self.device}")
            
            self.model.to(self.device)
            self.model.eval()
            
            # Загрузка маппинга меток
            label_mapping_path = f'{model_path}/label_mapping.json'
            if os.path.exists(label_mapping_path):
                with open(label_mapping_path, 'r', encoding='utf-8') as f:
                    label_mapping = json.load(f)
                    self.id2label = label_mapping['id2label']
                    self.label2id = label_mapping['label2id']
                print(f"Загружено {len(self.id2label)} меток")
            else:
                print("Используем маппинг из конфигурации модели")
                self.id2label = self.model.config.id2label
                self.label2id = self.model.config.label2id
                
        except Exception as e:
            print(f"Ошибка загрузки модели: {e}")
            return None
    
    def smart_tokenize(self, text):
        """
        Умная токенизация, которая лучше обрабатывает различные случаи
        """
        if not text or not text.strip():
            return []
        
        # Улучшенная токенизация с учетом различных символов
        tokens = []
        current_token = ""
        
        for char in text:
            # Если символ буквенно-цифровой или разрешенный специальный символ
            if char.isalnum() or char in ['-', '_', '@', '.', '+']:
                current_token += char
            else:
                # Сохраняем текущий токен если он не пустой
                if current_token:
                    tokens.append(current_token)
                    current_token = ""
                # Добавляем не-буквенно-цифровые символы как отдельные токены (кроме пробелов)
                if char.strip():
                    tokens.append(char)
        
        # Добавляем последний токен
        if current_token:
            tokens.append(current_token)
            
        return tokens
    
    def predict_entities(self, text):
        """
        Предсказание сущностей в тексте с улучшенной обработкой
        """
        if not text or not text.strip():
            return []
        
        try:
            # Используем умную токенизацию
            tokens = self.smart_tokenize(text)
            
            if not tokens:
                return []
            
            # Токенизация для модели
            encoding = self.tokenizer(
                tokens,
                is_split_into_words=True,
                padding=True,
                truncation=True,
                max_length=256,
                return_tensors="pt",
                return_offsets_mapping=True
            )
            
            # Предсказание
            with torch.no_grad():
                inputs = {k: v.to(self.device) for k, v in encoding.items()}
                outputs = self.model(**inputs)
                predictions = torch.argmax(outputs.logits, dim=2)
            
            # Обработка результатов
            entities = self._process_predictions(tokens, encoding, predictions)
            
            return entities
            
        except Exception as e:
            print(f"Ошибка при предсказании: {e}")
            return []
    
    def _process_predictions(self, original_tokens, encoding, predictions):
        """
        Обработка предсказаний с улучшенной логикой
        """
        entities = []
        word_ids = encoding.word_ids(batch_index=0)
        
        current_entity = ""
        current_entity_type = None
        
        for i, word_id in enumerate(word_ids):
            if word_id is None:
                # Специальные токены - пропускаем
                continue
            
            # Пропускаем padding
            if encoding['input_ids'][0][i] == self.tokenizer.pad_token_id:
                continue
            
            token = original_tokens[word_id] if word_id < len(original_tokens) else ""
            pred_id = predictions[0][i].item()
            label = self.id2label.get(str(pred_id), 'O')
            
            # Если это начало новой сущности
            if label.startswith('B-') or (label != 'O' and current_entity_type != label):
                # Сохраняем предыдущую сущность если есть
                if current_entity:
                    entities.append((current_entity.strip(), current_entity_type))
                
                # Начинаем новую сущность
                current_entity = token
                current_entity_type = label[2:] if label.startswith('B-') or label.startswith('I-') else label
            
            # Если продолжаем текущую сущность
            elif label != 'O' and current_entity_type == label:
                # Добавляем к текущей сущности (с пробелом если нужно)
                if token.strip() and not token.startswith(('.', ',', '!', '?', ':', ';')):
                    current_entity += " " + token
                else:
                    current_entity += token
            
            # Если сущность закончилась
            elif label == 'O' and current_entity:
                entities.append((current_entity.strip(), current_entity_type))
                current_entity = ""
                current_entity_type = None
        
        # Добавляем последнюю сущность если есть
        if current_entity:
            entities.append((current_entity.strip(), current_entity_type))
        
        return entities
    
    def predict_batch(self, texts):
        """
        Пакетное предсказание для списка текстов
        """
        results = []
        for text in texts:
            entities = self.predict_entities(text)
            results.append({
                'text': text,
                'entities': entities,
                'entities_count': len(entities)
            })
        return results

def process_single_file(input_file, model_path, output_file):
    """
    Обработка одного файла (JSON или CSV)
    """
    print(f"Обработка файла: {input_file}")
    
    # Определяем тип файла
    file_ext = os.path.splitext(input_file)[1].lower()
    
    if file_ext == '.json':
        return process_json_file(input_file, model_path, output_file)
    elif file_ext == '.csv':
        return process_csv_file(input_file, model_path, output_file)
    else:
        print(f"Неподдерживаемый формат файла: {file_ext}")
        return None

def process_json_file(json_file, model_path, output_file):
    """
    Обработка JSON файла с диалогами
    """
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"Ошибка загрузки JSON: {e}")
        return None
    
    # Извлекаем все сообщения
    messages = []
    for dialog in data:
        dialog_id = dialog.get('id', 'unknown')
        if 'dialogue' in dialog:
            for message_idx, message in enumerate(dialog['dialogue']):
                if 'text' in message and message['text'].strip():
                    # Обрабатываем многострочный текст
                    text_lines = message['text'].strip().split('\n')
                    for line_idx, line in enumerate(text_lines):
                        if line.strip():
                            messages.append({
                                'dialog_id': dialog_id,
                                'message_index': f"{message_idx}_{line_idx}",
                                'role': message.get('role', 'unknown'),
                                'text': line.strip(),
                                'topic': dialog.get('topic', 'unknown'),
                                'source': dialog.get('source', 'unknown')
                            })
    
    print(f"Найдено сообщений: {len(messages)}")
    return process_messages(messages, model_path, output_file)

def process_csv_file(csv_file, model_path, output_file):
    """
    Обработка CSV файла
    """
    try:
        df = pd.read_csv(csv_file)
    except Exception as e:
        print(f"Ошибка загрузки CSV: {e}")
        return None
    
    # Предполагаем, что текст в колонке 'text' или 'original_text'
    text_column = 'text' if 'text' in df.columns else 'original_text'
    if text_column not in df.columns:
        print("Не найдена колонка с текстом!")
        return None
    
    messages = []
    for idx, row in df.iterrows():
        text = row[text_column]
        if pd.notna(text) and str(text).strip():
            messages.append({
                'dialog_id': idx,
                'message_index': '0',
                'role': 'unknown',
                'text': str(text).strip(),
                'topic': 'unknown',
                'source': 'csv_file'
            })
    
    print(f"Найдено сообщений: {len(messages)}")
    return process_messages(messages, model_path, output_file)

def process_messages(messages, model_path, output_file):
    """
    Обработка списка сообщений
    """
    # Загрузка модели
    predictor = ImprovedNERPredictor(model_path)
    if predictor is None:
        print("Не удалось загрузить модель!")
        return None
    
    # Обработка сообщений
    results = []
    all_entities_list = []
    
    for i, message in enumerate(messages):
        if i % 50 == 0:
            print(f"Обработано {i}/{len(messages)} сообщений...")
        
        entities = predictor.predict_entities(message['text'])
        entities_str = "; ".join([f"{entity} -> {label}" for entity, label in entities])
        
        results.append({
            'dialog_id': message['dialog_id'],
            'message_index': message['message_index'],
            'role': message['role'],
            'topic': message['topic'],
            'source': message['source'],
            'text': message['text'],
            'entities': entities_str,
            'entities_count': len(entities)
        })
        
        # Собираем статистику по типам сущностей
        for _, label in entities:
            all_entities_list.append(label)
    
    # Сохранение результатов
    df = pd.DataFrame(results)
    df.to_csv(output_file, index=False, encoding='utf-8')
    
    # Статистика
    total_entities = df['entities_count'].sum()
    messages_with_entities = len(df[df['entities_count'] > 0])
    
    print(f"\nРезультаты сохранены в {output_file}")
    print(f"Обработано сообщений: {len(results)}")
    print(f"Сообщений с сущностями: {messages_with_entities}")
    print(f"Всего найдено сущностей: {total_entities}")
    
    # Анализ типов сущностей
    if all_entities_list:
        from collections import Counter
        entity_counts = Counter(all_entities_list)
        print("\nРаспределение типов сущностей:")
        for entity_type, count in entity_counts.most_common():
            print(f"  {entity_type}: {count}")
    
    return df

def interactive_mode(model_path):
    """
    Интерактивный режим для тестирования модели
    """
    print("\n" + "="*50)
    print("ИНТЕРАКТИВНЫЙ РЕЖИМ")
    print("Введите текст для распознавания сущностей (или 'quit' для выхода)")
    print("="*50)
    
    predictor = ImprovedNERPredictor(model_path)
    if predictor is None:
        print("Не удалось загрузить модель!")
        return
    
    while True:
        text = input("\nВведите текст: ").strip()
        
        if text.lower() in ['quit', 'exit', 'q']:
            break
        
        if not text:
            continue
        
        entities = predictor.predict_entities(text)
        
        print("\nРезультаты:")
        if entities:
            for entity, label in entities:
                print(f"  {entity} -> {label}")
        else:
            print("  Сущности не найдены")

def main():
    """
    Основная функция инференса
    """
    # ==================== КОНФИГУРАЦИЯ ====================
    MODEL_PATH = "ner-model-final"               # Путь к обученной модели
    INPUT_FILE = "test_data.json"                # Путь к входному файлу (JSON или CSV)
    OUTPUT_FILE = "ner_predictions.csv"          # Файл для сохранения результатов
    USE_INTERACTIVE_MODE = False                 # True для интерактивного режима, False для обработки файла
    # ======================================================
    
    print("=" * 50)
    print("ЗАПУСК ИНФЕРЕНСА NER МОДЕЛИ")
    print("=" * 50)
    
    if USE_INTERACTIVE_MODE:
        # Интерактивный режим
        interactive_mode(MODEL_PATH)
    else:
        # Обработка файла
        if not os.path.exists(INPUT_FILE):
            print(f"Файл {INPUT_FILE} не найден!")
            print("Переключаюсь в интерактивный режим...")
            interactive_mode(MODEL_PATH)
        else:
            process_single_file(INPUT_FILE, MODEL_PATH, OUTPUT_FILE)
    
    print("\n" + "=" * 50)
    print("ИНФЕРЕНС ЗАВЕРШЕН!")
    print("=" * 50)

if __name__ == "__main__":
    main()
