# training_improved.py
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import (
    AutoTokenizer, 
    AutoModelForTokenClassification,
    TrainingArguments,
    Trainer,
    DataCollatorForTokenClassification
)
import json
import numpy as np
import evaluate
import os
from sklearn.utils.class_weight import compute_class_weight

class NERDataset(Dataset):
    def __init__(self, examples, tokenizer, label2id, max_length=256):  # Увеличили max_length
        self.examples = examples
        self.tokenizer = tokenizer
        self.label2id = label2id
        self.max_length = max_length
    
    def __len__(self):
        return len(self.examples)
    
    def __getitem__(self, idx):
        example = self.examples[idx]
        tokens = example['tokens']
        labels = example['label_ids']
        
        # Токенизация с выравниванием меток
        encoding = self.tokenizer(
            tokens,
            is_split_into_words=True,
            padding='max_length',
            truncation=True,
            max_length=self.max_length,
            return_tensors='pt',
            return_offsets_mapping=True  # Добавили для отладки
        )
        
        # Выравнивание меток для BERT токенизации
        aligned_labels = []
        word_ids = encoding.word_ids()
        previous_word_idx = None
        
        for word_idx in word_ids:
            if word_idx is None:
                # Специальные токены ([CLS], [SEP], [PAD])
                aligned_labels.append(-100)
            elif word_idx != previous_word_idx:
                # Первый токен слова
                aligned_labels.append(labels[word_idx])
            else:
                # Последующие токены слова
                aligned_labels.append(-100)
            previous_word_idx = word_idx
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(aligned_labels, dtype=torch.long)
        }

def compute_metrics_improved(p, id2label):
    """
    Улучшенная функция вычисления метрик для NER
    """
    predictions, labels = p
    predictions = np.argmax(predictions, axis=2)
    
    # Убираем игнорируемые токены (метка -100)
    true_predictions = []
    true_labels = []
    
    for prediction, label in zip(predictions, labels):
        pred_line = []
        label_line = []
        for p, l in zip(prediction, label):
            if l != -100:
                pred_str = str(p.item())
                label_str = str(l)
                if pred_str in id2label and label_str in id2label:
                    pred_line.append(id2label[pred_str])
                    label_line.append(id2label[label_str])
        
        true_predictions.append(pred_line)
        true_labels.append(label_line)
    
    # Загружаем метрику для NER
    try:
        metric = evaluate.load("seqeval")
        results = metric.compute(predictions=true_predictions, references=true_labels)
        
        # Добавляем детальную статистику по классам
        detailed_results = {
            "precision": results["overall_precision"],
            "recall": results["overall_recall"],
            "f1": results["overall_f1"],
            "accuracy": results["overall_accuracy"],
        }
        
        # Добавляем метрики по каждому классу
        for key, value in results.items():
            if key not in ["overall_precision", "overall_recall", "overall_f1", "overall_accuracy"]:
                if isinstance(value, dict):
                    detailed_results[key] = value
        
        return detailed_results
        
    except Exception as e:
        print(f"Ошибка при вычислении метрик: {e}")
        return {"f1": 0.0, "precision": 0.0, "recall": 0.0, "accuracy": 0.0}

def calculate_class_weights(examples):
    """
    Вычисление весов классов для борьбы с дисбалансом
    """
    all_labels = []
    for example in examples:
        # Берем только реальные метки (не -100)
        labels = [label for label in example['label_ids'] if label != -100]
        all_labels.extend(labels)
    
    # Вычисляем веса классов
    unique_labels = list(set(all_labels))
    if len(unique_labels) > 1:
        class_weights = compute_class_weight(
            'balanced', 
            classes=unique_labels, 
            y=all_labels
        )
        return torch.tensor(class_weights, dtype=torch.float)
    else:
        return None

def load_training_data(data_dir):
    """
    Загрузка подготовленных данных
    """
    train_examples = []
    val_examples = []
    
    with open(f'{data_dir}/train_data.json', 'r', encoding='utf-8') as f:
        for line in f:
            train_examples.append(json.loads(line))
    
    with open(f'{data_dir}/val_data.json', 'r', encoding='utf-8') as f:
        for line in f:
            val_examples.append(json.loads(line))
    
    with open(f'{data_dir}/label_mapping.json', 'r', encoding='utf-8') as f:
        label_mapping = json.load(f)
        label2id = label_mapping['label2id']
        id2label = label_mapping['id2label']
    
    print(f"Загружено: {len(train_examples)} train, {len(val_examples)} val примеров")
    
    # Статистика по меткам
    all_train_labels = []
    for ex in train_examples:
        all_train_labels.extend([label for label in ex['ner_tags'] if label != 'O'])
    
    from collections import Counter
    label_counts = Counter(all_train_labels)
    print("Распределение меток в тренировочных данных:")
    for label, count in label_counts.most_common():
        print(f"  {label}: {count}")
    
    return train_examples, val_examples, label2id, id2label

def train_model_improved():
    """
    Улучшенная функция обучения модели
    """
    # Конфигурация
    MODEL_NAME = "bert-base-multilingual-cased"  # Можно попробовать "cointegrated/rubert-tiny2" для русского
    DATA_DIR = "training_data"
    OUTPUT_DIR = "ner-model-improved"
    
    # Загрузка данных и маппинга меток
    train_examples, val_examples, label2id, id2label = load_training_data(DATA_DIR)
    
    if not train_examples:
        print("Нет тренировочных данных!")
        return
    
    # Инициализация токенизатора и модели
    print("Загрузка токенизатора...")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    
    print("Загрузка модели...")
    model = AutoModelForTokenClassification.from_pretrained(
        MODEL_NAME,
        num_labels=len(label2id),
        id2label=id2label,
        label2id=label2id
    )
    
    # Вычисляем веса классов
    class_weights = calculate_class_weights(train_examples)
    if class_weights is not None:
        print("Веса классов:", class_weights)
        # Добавляем веса в модель (это потребует кастомной функции потерь)
    
    # Создание датасетов
    train_dataset = NERDataset(train_examples, tokenizer, label2id, max_length=256)
    val_dataset = NERDataset(val_examples, tokenizer, label2id, max_length=256)
    
    # Коллатор для батчей
    data_collator = DataCollatorForTokenClassification(
        tokenizer=tokenizer,
        padding=True
    )
    
    # Улучшенные аргументы обучения
    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        evaluation_strategy="epoch",
        learning_rate=2e-5,  # Уменьшили learning rate
        per_device_train_batch_size=16,  # Увеличили batch size если позволяет память
        per_device_eval_batch_size=16,
        num_train_epochs=8,  # Увеличили количество эпох
        weight_decay=0.01,
        save_strategy="epoch",
        load_best_model_at_end=True,
        metric_for_best_model="f1",
        greater_is_better=True,
        logging_dir=f"{OUTPUT_DIR}/logs",
        logging_steps=100,
        report_to=None,
        save_total_limit=3,
        dataloader_pin_memory=False,
        warmup_steps=500,  # Добавили warmup
        logging_first_step=True,
        seed=42,  # Для воспроизводимости
    )
    
    # Создание тренера
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        tokenizer=tokenizer,
        data_collator=data_collator,
        compute_metrics=lambda p: compute_metrics_improved(p, id2label),
    )
    
    # Запуск обучения
    print("Начало обучения...")
    try:
        # Предварительная оценка до обучения
        print("Предварительная оценка...")
        initial_eval = trainer.evaluate()
        print("Начальные метрики:", initial_eval)
        
        # Обучение
        trainer.train()
        
        # Финальная оценка
        final_eval = trainer.evaluate()
        print("Финальные метрики:")
        for key, value in final_eval.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
        
        # Сохранение модели
        trainer.save_model(f"{OUTPUT_DIR}-final")
        tokenizer.save_pretrained(f"{OUTPUT_DIR}-final")
        
        # Копируем label_mapping в финальную директорию
        import shutil
        shutil.copy2(f"{DATA_DIR}/label_mapping.json", f"{OUTPUT_DIR}-final/label_mapping.json")
        
        print(f"Модель сохранена в {OUTPUT_DIR}-final/")
        
    except Exception as e:
        print(f"Ошибка при обучении: {e}")
        import traceback
        traceback.print_exc()
        
        # Сохраняем модель даже при ошибке
        trainer.save_model(f"{OUTPUT_DIR}-emergency")
        tokenizer.save_pretrained(f"{OUTPUT_DIR}-emergency")
        print(f"Экстренная копия модели сохранена в {OUTPUT_DIR}-emergency/")
    
    return trainer

if __name__ == "__main__":
    train_model_improved()
